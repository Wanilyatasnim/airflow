# MLOps Retraining Pipeline

A complete production-ready MLOps project featuring automated ML model retraining using Apache Airflow, MLflow, and FastAPI.

## ğŸ—ï¸ Architecture

- **Apache Airflow**: Orchestrates the daily ML retraining pipeline
- **MLflow**: Tracks experiments, versions models, and manages model registry
- **FastAPI**: Serves model predictions via REST API
- **PostgreSQL**: Backend database for Airflow
- **Docker Compose**: Orchestrates all services

## ğŸ“ Project Structure

```
mlops-retraining/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ retrain_pipeline.py    # Main Airflow DAG
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ mlflow/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ artifacts/                 # MLflow artifacts
â”‚   â””â”€â”€ backend_store/             # MLflow backend store
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”œâ”€â”€ model_loader.py            # Model loading from MLflow
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract.py                 # Data extraction
â”‚   â”œâ”€â”€ preprocess.py              # Data preprocessing
â”‚   â”œâ”€â”€ train.py                   # Model training
â”‚   â”œâ”€â”€ evaluate.py                # Model evaluation & promotion
â”‚   â””â”€â”€ utils.py                   # Utility functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Raw data
â”‚   â”œâ”€â”€ processed/                 # Processed data
â”‚   â””â”€â”€ models/                    # Saved models
â””â”€â”€ docker-compose.yml
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose installed
- At least 4GB RAM available
- Ports 8080, 5000, and 8000 available

### Running the Project

1. **Start all services:**
   ```bash
   docker-compose up --build
   ```

2. **Access services:**
   - **Airflow UI**: http://localhost:8080
     - Username: `airflow`
     - Password: `airflow`
   - **MLflow UI**: http://localhost:5000
   - **FastAPI**: http://localhost:8000
   - **API Docs**: http://localhost:8000/docs

3. **Trigger the pipeline:**
   - Go to Airflow UI (http://localhost:8080)
   - Find the `ml_retraining_pipeline` DAG
   - Toggle it ON and trigger it manually or wait for the daily schedule

## ğŸ”„ Pipeline Workflow

The Airflow DAG runs daily and executes the following tasks:

1. **extract_data**: Downloads/loads the Titanic dataset
2. **preprocess**: Cleans data, engineers features, splits train/test
3. **train_model**: Trains Logistic Regression and Random Forest models
4. **evaluate_model**: Compares new models with production model
5. **load_model**: Loads best model for API service

## ğŸ“Š Model Training

The pipeline trains two models:
- **Logistic Regression**: Baseline model
- **Random Forest**: Ensemble model

Both models are:
- Logged to MLflow with metrics (accuracy, precision, recall, F1)
- Registered in MLflow Model Registry
- Compared against the current production model
- Promoted to production if they perform better

## ğŸ¯ API Endpoints

### Health Check
```bash
GET /health
```

### Single Prediction
```bash
POST /predict
Content-Type: application/json

{
  "pclass": 1,
  "sex": "female",
  "age": 25.0,
  "sibsp": 0,
  "parch": 0,
  "fare": 50.0,
  "embarked": "S"
}
```

### Batch Prediction
```bash
POST /predict/batch
Content-Type: application/json

{
  "instances": [
    {
      "pclass": 1,
      "sex": "female",
      "age": 25.0,
      "sibsp": 0,
      "parch": 0,
      "fare": 50.0,
      "embarked": "S"
    }
  ]
}
```

## ğŸ”§ Configuration

### Environment Variables

- `MLFLOW_TRACKING_URI`: MLflow server URI (default: `http://mlflow:5000`)
- `AIRFLOW__CORE__EXECUTOR`: Airflow executor (default: `LocalExecutor`)

### MLflow

- Tracking URI: `http://localhost:5000`
- Artifacts stored in Docker volume
- Model registry managed through MLflow UI

## ğŸ“ Notes

- The pipeline uses the Titanic dataset (synthetic if seaborn is unavailable)
- Models are automatically promoted to production if F1 score improves by at least 0.01
- The FastAPI service automatically loads the latest production model from MLflow
- All data and models are persisted in Docker volumes

## ğŸ› Troubleshooting

1. **Services not starting**: Check Docker logs with `docker-compose logs`
2. **Airflow DAG not appearing**: Wait a few minutes for Airflow to scan DAGs
3. **Model not loading**: Ensure MLflow service is running and a production model exists
4. **Port conflicts**: Modify ports in `docker-compose.yml`

## ğŸ“š Additional Resources

- [Airflow Documentation](https://airflow.apache.org/docs/)
- [MLflow Documentation](https://www.mlflow.org/docs/latest/index.html)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

## ğŸ“„ License

This project is provided as-is for educational and demonstration purposes.

